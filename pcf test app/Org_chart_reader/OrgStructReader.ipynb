{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/x-python"
   },
   "source": [
    "'''\n",
    "             *     ,MMM8&&&.            *\n",
    "                  MMMM88&&&&&    .\n",
    "                 MMMM88&&&&&&&\n",
    "     *           MMM88&&&&&&&&\n",
    "                 MMM88&&&&&&&&\n",
    "                 'MMM88&&&&&&'\n",
    "                   'MMM8&&&'      *    \n",
    "          |\\___/|     /\\___/\\\n",
    "          )     (     )    ~( .              '\n",
    "         =\\     /=   =\\~    /=\n",
    "           )===(       ) ~ (\n",
    "          /     \\     /     \\\n",
    "          |     |     ) ~   (\n",
    "         /       \\   /     ~ \\\n",
    "         \\       /   \\~     ~/\n",
    "  ____/\\_/\\__  _/_/\\_/\\__~__/_/\\_/\\_/\\_/\\_/\\_\n",
    "  |  |  |  |( (  |  |  | ))  |  |  |  |  |  |     \n",
    "  |  |  |  | ) ) |  |  |//|  |  |  |  |  |  |\n",
    "  |  |  |  |(_(  |  |  (( |  |  |  |  |  |  |     \n",
    "  |  |  |  |  |  |  |  |\\)|  |  |  |  |  |  |\n",
    "  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |   \n",
    "\n",
    "\n",
    "Things to do:\n",
    "    > green line - away from rect - crop verts - get text from orig image\n",
    "                                        > empty rectangles - ignore\n",
    "                                        > if dup text - ignore\n",
    "    \n",
    "    \n",
    "    \n",
    "    do differnt img processing for text and differnt for image and use the 1st one for ocr and second for rectangle\n",
    "    \n",
    "    Alternative to tesseract ? IBM datacap\n",
    "    \n",
    "    Logic for case where two sibling boxes can be connected\n",
    "    Logic for case where parent is there on the left most side instead of top \n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import PIL\n",
    "from scipy import misc\n",
    "from PIL import Image\n",
    "from pytesseract import image_to_string \n",
    "import pytesseract\n",
    "import argparse\n",
    "import re\n",
    "from GVision import gvision_ocr_text\n",
    "from GVision import gvision_ocr_perc\n",
    "from F_PATHS import find_paths\n",
    "import sys\n",
    "import math\n",
    "import os\n",
    "import shutil\n",
    "from F_Sign import verifySign "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_centre_vert= dict()\n",
    "dict_centre_rect= dict()\n",
    "dict_vfc_rect = dict()\n",
    "dict_vert_text = dict()\n",
    "dict_bvert_perc = dict()\n",
    "dict_centre_text = dict()\n",
    "dict_perc_rectCentre = dict()\n",
    "\n",
    "centres= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#path to tesseract installed on the machine\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = 'C:/Program Files (x86)/Tesseract-OCR/tesseract.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the image name :input_images/demo2.jpg\n",
      "Enter the client name :AZ Inc\n"
     ]
    }
   ],
   "source": [
    "#image_source = \"input_images/demo3.jpg\"\n",
    "#image_source = sys.argv[1]\n",
    "image_source = raw_input(\"Enter the image name :\")\n",
    "clientName = raw_input(\"Enter the client name :\")\n",
    "import ntpath\n",
    "out_file_name = os.path.splitext(ntpath.basename(image_source))[0]\n",
    "dir = 'output/'+ out_file_name\n",
    "if os.path.exists(dir):\n",
    "    shutil.rmtree(dir)\n",
    "os.makedirs(dir)\n",
    "\n",
    "f_out = dir+ \"/out\"\n",
    "f = open(f_out, 'w')\n",
    "img = cv2.imread(image_source)\n",
    "orig = img.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def angle_cos(p0, p1, p2):\n",
    "    d1, d2 = (p0-p1).astype('float'), (p2-p1).astype('float')\n",
    "    return abs( np.dot(d1, d2) / np.sqrt( np.dot(d1, d1)*np.dot(d2, d2) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#finding area of the org img\n",
    "\n",
    "height, width, channels = img.shape\n",
    "figArea = height*width\n",
    "\n",
    "minArea = figArea * 0.0014\n",
    "maxArea = figArea * 0.6\n",
    "maxCenLen = int(min([height,width]) * 0.022) \n",
    "\n",
    "#print \"minArea \", minArea\n",
    "#print \"maxArea \", maxArea\n",
    "#print \"maxCenLen\", maxCenLen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_rects(img):\n",
    "    img_org = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "    rects = []\n",
    "\n",
    "    img_neg = cv2.bitwise_not(img_org)\n",
    "\n",
    "    #getting RGB from img and so when we take just R, in a way it will be gray scale (0-255)\n",
    "    #aka r,g,b = cv2.split(img)\n",
    "    for i in range (0,2):\n",
    "        if i == 0 :\n",
    "            img = img_org\n",
    "        elif i == 1 :\n",
    "            img = img_neg\n",
    "\n",
    "        for gray in cv2.split(img):\n",
    "\n",
    "            #thresh from 0 - 255 with increments of 26\n",
    "            for thrs in xrange(0, 255, 26):\n",
    "                if thrs == 0:\n",
    "                    bin = cv2.Canny(gray, 0, 50, apertureSize=5)\n",
    "\n",
    "                    #dilating to thicken the edges for edge detection\n",
    "                    bin = cv2.dilate(bin, None)\n",
    "\n",
    "                else:\n",
    "\n",
    "                    #retval will be same as thrs unless until Otsuâ€™s Binarizatio is usd\n",
    "                    retval, bin = cv2.threshold(gray, thrs, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "                #hierar = [Next, Previous, First_Child, Parent] \n",
    "                # can later use it to remove rectangle inside another by checking hierarchy[0,i,3], where i != -1\n",
    "                _,contours, hierarchy = cv2.findContours(bin, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "                for cnt in contours:\n",
    "                    cnt_len = cv2.arcLength(cnt, True)\n",
    "                    cnt = cv2.approxPolyDP(cnt, 0.02*cnt_len, True)\n",
    "                    cnt_area = cv2.contourArea(cnt)\n",
    "                    if len(cnt) == 4 and cnt_area > minArea and cnt_area < maxArea and cv2.isContourConvex(cnt):\n",
    "\n",
    "                        #removing 1 outer list\n",
    "                        cnt = cnt.reshape(-1, 2)\n",
    "\n",
    "                        #the angles should roughly be 90, cos(90) = 0\n",
    "                        max_cos = np.max([angle_cos( cnt[i], cnt[(i+1) % 4], cnt[(i+2) % 4] ) for i in xrange(4)])\n",
    "                        if max_cos < 0.1:\n",
    "                            rects.append(cnt)\n",
    "    return rects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def r2centresDiff( (cX,cY), centres):\n",
    "    for i in range(-maxCenLen,maxCenLen):\n",
    "        for j in range(-maxCenLen,maxCenLen):\n",
    "            if(cX+i,cY+j) in centres:\n",
    "                return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_minMax(rect):\n",
    "    minX = min([rect[0][0],rect[1][0],rect[2][0],rect[3][0]])\n",
    "    maxX = max([rect[0][0],rect[1][0],rect[2][0],rect[3][0]])\n",
    "\n",
    "    minY = min([rect[0][1],rect[1][1],rect[2][1],rect[3][1]])\n",
    "    maxY = max([rect[0][1],rect[1][1],rect[2][1],rect[3][1]])\n",
    "\n",
    "    return (minX, maxX, minY, maxY)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_unique_rects(rects):\n",
    "    uniq_rects=[]\n",
    "    \n",
    "    \n",
    "    for rect in rects:\n",
    "        minX, maxX, minY, maxY = find_minMax(rect)\n",
    "        \n",
    "        cX = (minX + maxX)/2\n",
    "        cY = (minY + maxY)/2\n",
    "        \n",
    "        if ( r2centresDiff((cX,cY),centres)):\n",
    "            centre = (cX,cY)\n",
    "            centres.append(centre)\n",
    "            uniq_rects.append(rect)\n",
    "            dict_centre_rect[centre] = rect\n",
    "\n",
    "    return uniq_rects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def isRhombus(rect):\n",
    "    \n",
    "    \n",
    "    dist=[]\n",
    "    for i in range (0, len(rect)):\n",
    "        x1 = rect[i%4][0]\n",
    "        y1 = rect[i%4][1]\n",
    "\n",
    "        x2= rect[(i+1)%4][0]\n",
    "        y2= rect [(i+1)%4][1]\n",
    "        dist.append(math.sqrt((x2 - x1)**2 +  (y2 - y1)**2))\n",
    "    \n",
    "    if abs(dist[0] + dist[2] - dist[1] - dist[3]) <= 5:\n",
    "        print \"-----------------------\"\n",
    "        print \"Found a rhombus\"\n",
    "        print dist[0], dist[1], dist[2], dist [3]\n",
    "        print \"-----------------------\"\n",
    "        return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def removeEmptyRect(vfc, choice):\n",
    "    uniq = []\n",
    "    print \"Doing OCR ....... Finding Text\"\n",
    "    for vert in vfc:\n",
    "        minX, maxX, minY, maxY = vert\n",
    "        text= ocr(vert, choice)\n",
    "        #s = text.splitlines()\n",
    "        if u'' == text:\n",
    "            #print \"Found blank rectangle, hence removing it\"\n",
    "            cropped_img = orig[minY-1:maxY+1, minX-1:maxX+1] # Crop from y1:y2, x1:x2\n",
    "            magnified_img = misc.imresize(cropped_img, 50)\n",
    "            gray_img = cv2.cvtColor(magnified_img, cv2.COLOR_BGR2GRAY)\n",
    "            th_img = cv2.adaptiveThreshold(gray_img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n",
    "            #cv2.imwrite(\"emptyrect.png\",th_img)\n",
    "            \n",
    "        else:\n",
    "            print text\n",
    "            s = str(text)\n",
    "            stext = s.replace('\\n', '')\n",
    "            cX = (minX + maxX)/2\n",
    "            cY = (minY + maxY)/2\n",
    "            centre = (cX, cY)\n",
    "            dict_centre_text[(cX, cY)] = stext\n",
    "            dict_vert_text[vert] = stext\n",
    "            uniq.append(vert)\n",
    "            #f.write(\"%s\\n\" % stext)\n",
    "    return uniq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ocr(vert, choice):\n",
    "    \n",
    "    \n",
    "    minX, maxX, minY, maxY = vert\n",
    "    rect = dict_vfc_rect[(minX, maxX, minY, maxY)]\n",
    "    \n",
    "\n",
    "    #making the borders of the rhombus white\n",
    "    \n",
    "    orig2 = cv2.imread(image_source)\n",
    "    \n",
    "    for i in range (0, len(rect)):\n",
    "        x1 = rect[i%4][0]\n",
    "        y1 = rect[i%4][1]\n",
    "\n",
    "        x2= rect[(i+1)%4][0]\n",
    "        y2= rect[(i+1)%4][1]\n",
    "\n",
    "        cv2.line(orig2,(x1,y1),(x2,y2),(255,255,255),20)\n",
    "\n",
    "    #if rhombus/diamond dont rotate\n",
    "    if isRhombus(rect):\n",
    "        \n",
    "        cropped_img = orig2[ minY+1:maxY-1, minX+1:maxX-1]\n",
    "        cv2.imwrite(\"cropped2.png\",cropped_img)\n",
    "        \n",
    "    #else rotate if rectangle\n",
    "    else: \n",
    "        transformImg(rect)\n",
    "    \n",
    "    if choice == \"gtesseract\":\n",
    "        orig3 = cv2.imread(\"cropped2.png\")\n",
    "        height, width, channels= orig3.shape\n",
    "        #cropped_img = orig3[10:height-10, 10:width-10] # Crop from y1:y2, x1:x2\n",
    "        cropped_img = orig3.copy()\n",
    "        \n",
    "        magnified_img = misc.imresize(cropped_img, 50)\n",
    "        gray_img = cv2.cvtColor(magnified_img, cv2.COLOR_BGR2GRAY)\n",
    "        th_img = cv2.adaptiveThreshold(gray_img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n",
    "        magnified_img = misc.imresize(th_img, 500)\n",
    "\n",
    "        kernel = np.ones((2,2), np.uint8)\n",
    "        th_img = cv2.dilate(magnified_img, kernel, iterations=4)\n",
    "\n",
    "        cv2.imwrite(\"cropped.png\",th_img)\n",
    "        text= image_to_string(Image.open('cropped.png'))\n",
    "        \n",
    "        \n",
    "    elif choice == \"gvision\":\n",
    "        \n",
    "        or_im = cv2.imread(\"cropped2.png\")\n",
    "        mag_im = misc.imresize(or_im, 500)\n",
    "        cv2.imwrite(\"cropped2.png\",mag_im)\n",
    "        text = gvision_ocr_text([\"cropped2.png\"])\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        print \"INVALID CHOICE\"\n",
    "        \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gray_img = cv2.cvtColor(orig, cv2.COLOR_BGR2GRAY)\n",
    "th_img = cv2.adaptiveThreshold(gray_img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n",
    "#cv2.imwrite(\"12345.png\",th_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def removeRectInsideOther(rects):\n",
    "    \n",
    "    vertForCropping= []\n",
    "    vertToIgnore=[]\n",
    "    uniq_rects = []\n",
    "  \n",
    "    combinationList = []\n",
    "    for x in range(0, len(rects)):\n",
    "        combinationList.append(x)\n",
    "    \n",
    "    for r in rects:\n",
    "        vertForCropping.append(find_minMax(r))\n",
    "        \n",
    "    \n",
    "    a = iter(combinationList)\n",
    "    import itertools\n",
    "    combinations=[]\n",
    "    combinations.extend(itertools.combinations(a, 2))\n",
    "    \n",
    "    \n",
    "    for c in combinations:\n",
    "        minX1, maxX1, minY1, maxY1 = find_minMax(rects[c[0]])\n",
    "        minX2, maxX2, minY2, maxY2 = find_minMax(rects[c[1]])\n",
    "        \n",
    "        #second rectangle lies inside first = use 1st\n",
    "        if minX2 > minX1 and minY2 > minY1 and maxX2 < maxX1 and maxY2 < maxY1:\n",
    "            vertToIgnore.append((minX2, maxX2, minY2, maxY2))\n",
    "            \n",
    "       \n",
    "        \n",
    "        #opposite to first condition\n",
    "        elif minX2 < minX1 and minY2 < minY1 and maxX2 > maxX1 and maxY2 > maxY1:\n",
    "             vertToIgnore.append((minX1, maxX1, minY1, maxY1))\n",
    "    \n",
    "        \n",
    "    \n",
    "    uniq_vertForCropping = [x for x in vertForCropping if x not in vertToIgnore]\n",
    "    \n",
    "\n",
    "    return uniq_vertForCropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from transform import four_point_transform\n",
    "\n",
    "def transformImg(rect):\n",
    "    import os\n",
    "    import time\n",
    "    \n",
    "    image = cv2.imread(image_source)\n",
    "    pts = np.array(eval(\"[(rect[0][0],  rect[0][1]), (rect[1][0], rect[1][1]), (rect[2][0], rect[2][1]), (rect[3][0],rect[3][1])]\"), dtype = \"float32\")\n",
    "    \n",
    "    warped = four_point_transform(image, pts)\n",
    "    cv2.imwrite(\"cropped2.png\", warped)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeVFCRect_Dict(rects):\n",
    "    for r in rects:\n",
    "        minX, maxX, minY, maxY = find_minMax(r)\n",
    "        dict_vfc_rect[(minX, maxX, minY, maxY)]= r\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getClientCentre(clientName):\n",
    "    minY = 1000\n",
    "    clientCentre = \"\"\n",
    "    for centre in dict_centre_text.keys():\n",
    "        name = dict_centre_text[centre]\n",
    "        if str(clientName) == str(name):\n",
    "            print \"matched \", name\n",
    "            cY = centre[1]\n",
    "            if cY < minY:\n",
    "                minY = cY\n",
    "                clientCentre = centre\n",
    "                \n",
    "    return clientCentre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def makeCentreVFC_Dict(uniq):\n",
    "    uniq_centres= []\n",
    "    for vfc in uniq:\n",
    "        minX, maxX, minY, maxY = vfc\n",
    "        cX = (minX + maxX)/2\n",
    "        cY = (minY + maxY)/2\n",
    "        \n",
    "        centre = (cX,cY)\n",
    "        dict_centre_vert[centre] = [vfc]\n",
    "        uniq_centres.append(centre)\n",
    "    return uniq_centres\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def percRelations(uniq_centres):\n",
    "\n",
    "    for d in dict_vert_perc.keys():\n",
    "        min_dist = 100000000000000000\n",
    "        perc = dict_vert_perc[d]\n",
    "        pcX = (d[0] + d[4])/2\n",
    "        pcY = (d[1] + d[5])/2\n",
    "        rc = \"\"\n",
    "        for rect_centre in uniq_centres:\n",
    "            rcX = rect_centre[0]\n",
    "            rcY = rect_centre[1]\n",
    "            dist = math.sqrt((rcX - pcX)**2 +  (rcY - pcY)**2)\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                rc = (rcX, rcY)\n",
    "        \n",
    "        import unicodedata\n",
    "        perc = unicodedata.normalize('NFKD', perc).encode('ascii','ignore')\n",
    "        perc.replace(\"'\", '')\n",
    "        dict_perc_rectCentre[rc] = perc\n",
    "\n",
    "    #print dict_perc_rectCentre\n",
    "    \n",
    "    f.write('\\n')\n",
    "    for rect_centre in dict_perc_rectCentre.keys():\n",
    "        perc = dict_perc_rectCentre[rect_centre]\n",
    "        rect_text = dict_centre_text[rect_centre]\n",
    "        print \"\\nPercentage \", perc, \" is associated with \", rect_text\n",
    "        f.write(\"\\nPercentage %s is associated with %s\" % (perc, rect_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signs/BJFranklin.jpg\n",
      "12 % - Match with :  BJFranklin.jpg\n",
      "signs/Cameron.jpg\n",
      "20 % - Match with :  Cameron.jpg\n",
      "signs/Cassa.jpg\n",
      "36 % - Match with :  Cassa.jpg\n",
      "signs/DevAnand.jpg\n",
      "31 % - Match with :  DevAnand.jpg\n",
      "signs/Frank.jpg\n",
      "28 % - Match with :  Frank.jpg\n",
      "signs/JohnC.jpg\n",
      "33 % - Match with :  JohnC.jpg\n",
      "signs/johnF.jpg\n",
      "93 % - Match with :  johnF.jpg\n",
      "signs/martha.jpg\n",
      "3 % - Match with :  martha.jpg\n",
      "signs/Stanlee.jpg\n",
      "7 % - Match with :  Stanlee.jpg\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Signature found in the Document  input_images/demo2.jpg  and it matches with  signs/johnF.jpg\n",
      "............ Start finding rectangles ...............\n",
      "Doing OCR ....... Finding Text\n",
      "ACE planning\n",
      "\n",
      "BO Unit\n",
      "\n",
      "GPB Holdings\n",
      "\n",
      "ITO Ltd\n",
      "\n",
      "ACT INC\n",
      "\n",
      "CSI Cells\n",
      "\n",
      "Energy Services\n",
      "\n",
      "AZ Inc\n",
      "\n",
      "ENRON Ltd\n",
      "\n",
      "\n",
      "Total number of entities found =  9\n",
      "\n",
      "Doing OCR ....... Finding Percentages %\n",
      "51\n",
      "49\n",
      "50\n",
      "50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import win32api\n",
    "\n",
    "if verifySign(image_source):\n",
    "    win32api.MessageBox(0, 'Signature Matched', 'Success')\n",
    "\n",
    "else:\n",
    "    win32api.MessageBox(0, 'Signature Not Matched', 'Warning')\n",
    "    sys.exit()\n",
    "\n",
    "rects = find_rects(img)\n",
    "# print \"before removing duplicate \",len(rects)\n",
    "# img = cv2.imread(image_source)\n",
    "# cv2.drawContours(img, rects, -1, (0,255,0), 3)\n",
    "# cv2.imwrite('qwwe1.jpg', img)\n",
    "\n",
    "uniq_rects = find_unique_rects(rects)\n",
    "# print \"after removing duplicate \",len(uniq_rects)\n",
    "# img = cv2.imread(image_source)\n",
    "# cv2.drawContours(img, rects, -1, (0,255,255), 3)\n",
    "# cv2.imwrite('qwwe2.jpg', img)\n",
    "\n",
    "makeVFCRect_Dict(uniq_rects)\n",
    "\n",
    "vfc = removeRectInsideOther(uniq_rects)\n",
    "#print \"before removing empty \",len(vfc)\n",
    "\n",
    "\n",
    "print \"............ Start finding rectangles ...............\"\n",
    "# uniq_vfc = removeEmptyRect(vfc, \"gtesseract\")\n",
    "uniq_vfc = removeEmptyRect(vfc, \"gvision\")\n",
    "# print \"after removing empty \",len(uniq_vfc)\n",
    "\n",
    "uniq_centres = makeCentreVFC_Dict(uniq_vfc)\n",
    "\n",
    "print \"\\nTotal number of entities found = \", len(uniq_vfc)\n",
    "f.write(\"\\nTotal number of entitites found = %s\" % len(uniq_vfc))\n",
    "\n",
    "\n",
    "out_file_name = os.path.splitext(ntpath.basename(image_source))[0]\n",
    "\n",
    "\n",
    "img = cv2.imread(image_source)\n",
    "for vert in uniq_vfc:\n",
    "    cv2.rectangle(img,(vert[0]-2,vert[2]-2),(vert[1]+2,vert[3]+2),(0,0,255),3)\n",
    "s = dir + \"/text.jpg\"\n",
    "cv2.imwrite(s,img)\n",
    "\n",
    "print \"\\nDoing OCR ....... Finding Percentages %\"\n",
    "\n",
    "img = cv2.imread(image_source)\n",
    "dict_vert_perc = gvision_ocr_perc(image_source)\n",
    "for d in dict_vert_perc.keys():\n",
    "    cv2.rectangle(img,(d[0]-2,d[1]-2),(d[4]+2,d[5]+2),(21,213,55),3)\n",
    "s = dir + \"/perc.jpg\"\n",
    "cv2.imwrite(s,img)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print dict_centre_text\n",
    "clientName  = \"HSBC Holdings plc\"\n",
    "clientCentre = getClientCentre(clientName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Percentage  50  is associated with  Energy Services\n",
      "\n",
      "Percentage  49  is associated with  BO Unit\n",
      "\n",
      "Percentage  51  is associated with  AZ Inc\n",
      "\n",
      "Percentage  50  is associated with  ACT INC\n"
     ]
    }
   ],
   "source": [
    "percRelations(uniq_centres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      ".... Finding relationships between entities ...... \n",
      "Path found between  BO Unit  and  ACT INC\n",
      "Path found between  ACT INC  and  AZ Inc\n",
      "Path found between  Energy Services  and  ENRON Ltd\n",
      "Path found between  ITO Ltd  and  ACT INC\n",
      "Path found between  ITO Ltd  and  Energy Services\n",
      "Path found between  ACE planning  and  ITO Ltd\n",
      "Path found between  ACE planning  and  CSI Cells\n",
      "Path found between  GPB Holdings  and  CSI Cells\n",
      "\n",
      "\n",
      "Total number of connections =  8\n",
      "\n",
      "\n",
      "Number of levels excluding client =  5\n"
     ]
    }
   ],
   "source": [
    "parentChildDict = find_paths(uniq_vfc,dict_centre_vert,uniq_centres,image_source, clientCentre, dict_centre_text,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
