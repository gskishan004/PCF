{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from shapedetector import ShapeDetector\n",
    "import argparse\n",
    "import imutils\n",
    "from PIL import Image\n",
    "from pytesseract import image_to_string as its\n",
    "import pytesseract\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy import misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = 'C:/Program Files (x86)/Tesseract-OCR/tesseract.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#image = cv2.imread(\"Input.png\")\n",
    "image = cv2.imread(\"lvl2inp.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncode to enhance the image\\n\\n'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "code to enhance the image\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the query image, compute the ratio of the old height\n",
    "# to the new height, clone it, and resize it\n",
    "ratio = image.shape[0] / 300.0\n",
    "orig = image.copy()\n",
    "#image = imutils.resize(image, height = 300)\n",
    " \n",
    "# convert the image to grayscale, blur it, and find edges\n",
    "# in the image\n",
    "image = orig\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.bilateralFilter(gray, 11, 17, 17)\n",
    "edged = cv2.Canny(gray, 30, 200)\n",
    "#cv2.imshow('image',edged)\n",
    "#cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "# find contours in the edged image, keep only the largest\n",
    "# ones, and initialize our screen contour\n",
    "(cnts, _) = cv2.findContours(gray.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "print len(cnts)\n",
    "#cnts = sorted(cnts, key = cv2.contourArea, reverse = True)[:10]\n",
    "\n",
    "screenCnt = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#vertices of rectangles\n",
    "testArea = []\n",
    "#vertex for cropping\n",
    "vfc = []\n",
    "#list of centres\n",
    "cen = []\n",
    "minX = 1000000000\n",
    "minY = 1000000000\n",
    "maxX = 0\n",
    "maxY = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(107, 381) (241, 443)\n",
      "8308\n",
      "MR X\n",
      "100%\n",
      "#--------------------------#\n",
      "(502, 368) (648, 434)\n",
      "9636\n",
      "MR Y\n",
      "100%\n",
      "#--------------------------#\n",
      "(98, 199) (239, 264)\n",
      "9165\n",
      "MR A\n",
      "30%\n",
      "#--------------------------#\n",
      "(356, 198) (527, 266)\n",
      "11628\n",
      "MISS B\n",
      "25%\n",
      "#--------------------------#\n",
      "(644, 196) (816, 270)\n",
      "12728\n",
      "MR C\n",
      "45%\n",
      "#--------------------------#\n",
      "(324, 48) (466, 118)\n",
      "9940\n",
      "100%\n",
      "#--------------------------#\n"
     ]
    }
   ],
   "source": [
    "for c in cnts:\n",
    "    area = cv2.approxPolyDP(c, 1, True)\n",
    "    if len(area) == 4 :\n",
    "        testArea.append(c)\n",
    "\n",
    "\n",
    "height, width, channels = image.shape\n",
    "figArea = height*width\n",
    "\n",
    "\n",
    "for v in testArea:\n",
    "    minX = 1000000000\n",
    "    minY = 1000000000\n",
    "    maxX = 0\n",
    "    maxY = 0\n",
    "    for a in v:\n",
    "        x= a[0][0]\n",
    "        y= a[0][1]\n",
    "        if x<=minX and y<=minY:\n",
    "            minX=x\n",
    "            minY=y\n",
    "        if x>=maxX and y>=maxY:\n",
    "            maxX=x\n",
    "            maxY=y\n",
    "    \n",
    "    area = (maxX - minX)*(maxY - minY)\n",
    "    \n",
    "    #area of the reactangles should be greater than 0.0014 and less than 0.6 the total area of the image\n",
    "    minArea = figArea * 0.0014\n",
    "    maxArea = figArea * 0.6\n",
    "    \n",
    "    if area>minArea and area<maxArea:\n",
    "        \n",
    "        print (minX,minY),(maxX,maxY)\n",
    "        print area\n",
    "        \n",
    "        cv2.rectangle(image,(minX,minY),(maxX,maxY),(35,245,198),3)\n",
    "        vfc.append([(minX,minY),(maxX,maxY)])\n",
    "        cen.append([((minX+maxX)/2),((minY+maxY)/2)])\n",
    "        \n",
    "        # cropping the rectangles from the image and doing the OCR\n",
    "       \n",
    "        cropped_img = image[minY:maxY, minX:maxX] # Crop from y1:y2, x1:x2\n",
    "        magnified_img = misc.imresize(cropped_img, 500)\n",
    "        cv2.imwrite(\"cropped.png\",magnified_img)\n",
    "        cv2.waitKey(0)\n",
    "        t= its(Image.open('cropped.png'))\n",
    "\n",
    "        print t\n",
    "        '''\n",
    "        dict_centre_text[centre]= t\n",
    "        import string\n",
    "        s = string.split(t, '\\n') #s[0] = entity name , s[1] = % owned\n",
    "        if len(s) <2:\n",
    "            dict_centre_names[centre]= s[0]\n",
    "            dict_name_perc[s[0]] = \"NA\"\n",
    "        else:\n",
    "            dict_centre_names[centre]= s[0] \n",
    "            dict_name_perc[s[0]] = s[1]\n",
    "            \n",
    "        text.append(t)\n",
    "        '''\n",
    "\n",
    "        print \"#--------------------------#\"\n",
    "        \n",
    "        \n",
    "    cv2.imshow(\"image\",image)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def r2centresDiff( (cX,cY), centres):\n",
    "    for i in range(-2,3):\n",
    "        for j in range(-2,3):\n",
    "            if(cX+i,cY+j) in centres:\n",
    "                return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X=[]\n",
    "Y=[]\n",
    "centres=[]\n",
    "rectangles=[]\n",
    "finalRectangles=[]\n",
    "vertForCropping=[]\n",
    "dict_centre_vert = dict()\n",
    "dict_centre_text=dict()\n",
    "dict_centre_names=dict()\n",
    "dict_name_perc=dict()\n",
    "text=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# loop over our contours\\nfrom scipy import misc\\n\\nfor c in cnts:\\n    # approximate the contour\\n    peri = cv2.arcLength(c, True)\\n    approx = cv2.approxPolyDP(c, 0.02 * peri, True)\\n    rectangles.append(approx)\\n    M = cv2.moments(c)\\n    cX = int(M[\"m10\"] / M[\"m00\"])\\n    cY = int(M[\"m01\"] / M[\"m00\"])\\n    \\n    #removing duplicate contour by checking centres\\n    \\n   \\n    # contour will have len(approx) == 4 for shape with 4 sides\\n#if len(approx) >3 and cv2.isContourConvex(c) == True:\\n    if len(approx) ==4 :\\n        if ( r2centresDiff((cX,cY),centres)):\\n            centres.append((cX,cY))\\n            screenCnt = approx\\n            finalRectangles.append(approx)           \\n            cv2.drawContours(image, [screenCnt], -1, (0, 255, 0), 3)\\n            \\n            # getting the vertices for cropping the image\\n\\n\\n            minX = 1000000000\\n            minY = 1000000000\\n\\n            maxX = 0\\n            maxY = 0\\n\\n            for vert in approx:\\n                for c in vert:\\n                    x= c[0]\\n                    y= c[1]\\n                    if x<=minX and y<=minY:\\n                        minX=x\\n                        minY=y\\n                    if x>=maxX and y>=maxY:\\n                        maxX=x\\n                        maxY=y\\n\\n            centre = (cX,cY)\\n            diagonal_verts = [(minX,minY),(maxX,maxY)]\\n            dict_centre_vert[centre] = diagonal_verts\\n            vertForCropping.append(diagonal_verts)\\n            \\n            # cropping the rectangles from the image and doing the OCR\\n            cropped_img = image[diagonal_verts[0][1]:diagonal_verts[1][1], diagonal_verts[0][0]:diagonal_verts[1][0]] # Crop from y1:y2, x1:x2\\n            magnified_img = misc.imresize(cropped_img, 500)\\n            cv2.imwrite(\"cropped.png\",magnified_img)\\n            cv2.waitKey(0)\\n            t= its(Image.open(\\'cropped.png\\'))\\n\\n            print t\\n            dict_centre_text[centre]= t\\n            import string\\n            s = string.split(t, \\'\\n\\') #s[0] = entity name , s[1] = % owned\\n            if len(s) <2:\\n                dict_centre_names[centre]= s[0]\\n                dict_name_perc[s[0]] = \"NA\"\\n            else:\\n                dict_centre_names[centre]= s[0] \\n                dict_name_perc[s[0]] = s[1]\\n            \\n            print \"------------------------\"\\n            text.append(t)\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# loop over our contours\n",
    "\n",
    "for c in cnts:\n",
    "    # approximate the contour\n",
    "    peri = cv2.arcLength(c, True)\n",
    "    approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "    rectangles.append(approx)\n",
    "    M = cv2.moments(c)\n",
    "    cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "    cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "    \n",
    "    #removing duplicate contour by checking centres\n",
    "    \n",
    "   \n",
    "    # contour will have len(approx) == 4 for shape with 4 sides\n",
    "#if len(approx) >3 and cv2.isContourConvex(c) == True:\n",
    "    if len(approx) ==4 :\n",
    "        if ( r2centresDiff((cX,cY),centres)):\n",
    "            centres.append((cX,cY))\n",
    "            screenCnt = approx\n",
    "            finalRectangles.append(approx)           \n",
    "            cv2.drawContours(image, [screenCnt], -1, (0, 255, 0), 3)\n",
    "            \n",
    "            # getting the vertices for cropping the image\n",
    "\n",
    "\n",
    "            minX = 1000000000\n",
    "            minY = 1000000000\n",
    "\n",
    "            maxX = 0\n",
    "            maxY = 0\n",
    "\n",
    "            for vert in approx:\n",
    "                for c in vert:\n",
    "                    x= c[0]\n",
    "                    y= c[1]\n",
    "                    if x<=minX and y<=minY:\n",
    "                        minX=x\n",
    "                        minY=y\n",
    "                    if x>=maxX and y>=maxY:\n",
    "                        maxX=x\n",
    "                        maxY=y\n",
    "\n",
    "            centre = (cX,cY)\n",
    "            diagonal_verts = [(minX,minY),(maxX,maxY)]\n",
    "            dict_centre_vert[centre] = diagonal_verts\n",
    "            vertForCropping.append(diagonal_verts)\n",
    "            \n",
    "            # cropping the rectangles from the image and doing the OCR\n",
    "            cropped_img = image[diagonal_verts[0][1]:diagonal_verts[1][1], diagonal_verts[0][0]:diagonal_verts[1][0]] # Crop from y1:y2, x1:x2\n",
    "            magnified_img = misc.imresize(cropped_img, 500)\n",
    "            cv2.imwrite(\"cropped.png\",magnified_img)\n",
    "            cv2.waitKey(0)\n",
    "            t= its(Image.open('cropped.png'))\n",
    "\n",
    "            print t\n",
    "            dict_centre_text[centre]= t\n",
    "            import string\n",
    "            s = string.split(t, '\\n') #s[0] = entity name , s[1] = % owned\n",
    "            if len(s) <2:\n",
    "                dict_centre_names[centre]= s[0]\n",
    "                dict_name_perc[s[0]] = \"NA\"\n",
    "            else:\n",
    "                dict_centre_names[centre]= s[0] \n",
    "                dict_name_perc[s[0]] = s[1]\n",
    "            \n",
    "            print \"------------------------\"\n",
    "            text.append(t)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(153, 257), (393, 378)]\n",
      "[(920, 433), (1122, 559)]\n",
      "[(580, 445), (789, 550)]\n",
      "[(685, 227), (891, 329)]\n",
      "[(424, 52), (619, 150)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#drawing lines over the boxes\n",
    "for v in vertForCropping:\n",
    "    print v\n",
    "    cv2.rectangle(image,(v[0][0]-2,v[0][1]-2),(v[1][0]+2,v[1][1]+2),(123,123,255),3)\n",
    "cv2.imshow(\"image\",image) \n",
    "cv2.waitKey(0)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom scipy import misc\\n\\nfor vert in vertForCropping:\\n    cropped_img = image[vert[0][1]:vert[1][1], vert[0][0]:vert[1][0]] # Crop from y1:y2, x1:x2\\n    magnified_img = misc.imresize(cropped_img, 500)\\n    cv2.imwrite(\"cropped.png\",magnified_img)\\n    cv2.waitKey(0)\\n    t= its(Image.open(\\'cropped.png\\'))\\n\\n    print t\\n    print \"!\"\\n    text.append(t)\\n'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cv2.imshow(\"Image\", image)\n",
    "#cv2.waitKey(0)\n",
    "'''\n",
    "from scipy import misc\n",
    "\n",
    "for vert in vertForCropping:\n",
    "    cropped_img = image[vert[0][1]:vert[1][1], vert[0][0]:vert[1][0]] # Crop from y1:y2, x1:x2\n",
    "    magnified_img = misc.imresize(cropped_img, 500)\n",
    "    cv2.imwrite(\"cropped.png\",magnified_img)\n",
    "    cv2.waitKey(0)\n",
    "    t= its(Image.open('cropped.png'))\n",
    "\n",
    "    print t\n",
    "    print \"!\"\n",
    "    text.append(t)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of final rect 0\n",
      "vert {}\n",
      "text {}\n",
      "names {}\n",
      "perc {}\n"
     ]
    }
   ],
   "source": [
    "print \"length of final rect\",len(finalRectangles)\n",
    "print \"vert\",(dict_centre_vert)\n",
    "print \"text\",(dict_centre_text)\n",
    "print \"names\",(dict_centre_names)\n",
    "print \"perc\",(dict_name_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(273, 316), (1021, 495), (684, 496), (788, 277), (521, 100)]\n"
     ]
    }
   ],
   "source": [
    "print centres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# getting the vertices for cropping the image\\n\\nfor rect in finalRectangles:\\n    minX = 100000\\n    minY = 100000\\n    \\n    maxX = 0\\n    maxY = 0\\n    \\n    for vert in rect:\\n        for c in vert:\\n            x= c[0]\\n            y= c[1]\\n            if x<=minX and y<=minY:\\n                minX=x\\n                minY=y\\n            if x>=maxX and y>=maxY:\\n                maxX=x\\n                maxY=y\\n                \\n            \\n    vertForCropping.append([(minX,minY),(maxX,maxY)])\\n'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "# getting the vertices for cropping the image\n",
    "\n",
    "for rect in finalRectangles:\n",
    "    minX = 100000\n",
    "    minY = 100000\n",
    "    \n",
    "    maxX = 0\n",
    "    maxY = 0\n",
    "    \n",
    "    for vert in rect:\n",
    "        for c in vert:\n",
    "            x= c[0]\n",
    "            y= c[1]\n",
    "            if x<=minX and y<=minY:\n",
    "                minX=x\n",
    "                minY=y\n",
    "            if x>=maxX and y>=maxY:\n",
    "                maxX=x\n",
    "                maxY=y\n",
    "                \n",
    "            \n",
    "    vertForCropping.append([(minX,minY),(maxX,maxY)])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(153, 257), (393, 378)], [(920, 433), (1122, 559)], [(580, 445), (789, 550)], [(685, 227), (891, 329)], [(424, 52), (619, 150)]]\n"
     ]
    }
   ],
   "source": [
    "print vertForCropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dict_centre_vert = dict(zip(centres, vertForCropping))\n",
    "#print (dict_centre_vert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Converting the img to negative and removing text\n",
    "negImg = cv2.bitwise_not(image)\n",
    "for vert in vertForCropping:\n",
    "    cv2.rectangle(negImg,(vert[0][0]-2,vert[0][1]-2),(vert[1][0]+2,vert[1][1]+2),(255,255,255),-1)\n",
    "\n",
    "#cv2.imshow(\"image\",negImg)\n",
    "#cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"neg.png\",negImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from Queue import Queue\n",
    "from PIL import Image\n",
    "#(273, 316), (1021, 495), (684, 496), (788, 277), (521, 100)\n",
    "#start = (521, 100)\n",
    "#end  = (1021, 495)\n",
    "\n",
    "def iswhite(value):\n",
    "    if value == (255,255,255):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def getNewVertForCropping(vertForCropping, rect1_centre,  rect2_centre):\n",
    "    newVertForCropping=[]\n",
    "    \n",
    "    negImg2=negImg.copy()\n",
    "    \n",
    "    \n",
    "    rect1_x1, rect1_y1 = dict_centre_vert[rect1_centre][0]\n",
    "    rect1_x2, rect1_y2 = dict_centre_vert[rect1_centre][1]\n",
    "    \n",
    "    rect2_x1, rect2_y1 = dict_centre_vert[rect2_centre][0]\n",
    "    rect2_x2, rect2_y2 = dict_centre_vert[rect2_centre][1]\n",
    "\n",
    "    #rect1_x1, rect1_y1, rect1_x2, rect1_y2 = exclude_p1[0][0], exclude_p1[0][1], exclude_p1[1][0], exclude_p1[1][1]\n",
    "    #rect2_x1, rect2_y1, rect2_x2, rect2_y2 = exclude_p2[0][0], exclude_p2[0][1], exclude_p2[1][0], exclude_p2[1][1]\n",
    "  \n",
    "    \n",
    "    for vert in vertForCropping:\n",
    "\n",
    "        #this box which is being considered leave it white\n",
    "        if vert[0][0] == rect1_x1 and vert[0][1] ==rect1_y1 and vert[1][0] ==rect1_x2 and vert[1][1] ==rect1_y2:\n",
    "            pass\n",
    "        elif vert[0][0] == rect2_x1 and vert[0][1] ==rect2_y1 and vert[1][0] ==rect2_x2 and vert[1][1] ==rect2_y2:\n",
    "            pass\n",
    "        else:\n",
    "            #make all other boxes black\n",
    "            cv2.rectangle(negImg2,(vert[0][0]-4,vert[0][1]-4),(vert[1][0]+4,vert[1][1]+4),(0,0,0),-1)\n",
    "            cv2.imwrite('blackRectNewNeg.png', negImg2)\n",
    "            #cv2.imshow('image',negImg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def getadjacent(n):\n",
    "    x,y = n\n",
    "    return [(x-1,y),(x,y-1),(x+1,y),(x,y+1)]\n",
    "\n",
    "def BFS(start, end, pixels):\n",
    "\n",
    "    queue = Queue()\n",
    "    queue.put([start]) # Wrapping the start tuple in a list\n",
    "\n",
    "    while not queue.empty():\n",
    "\n",
    "        path = queue.get() \n",
    "        pixel = path[-1]\n",
    "\n",
    "        if pixel == end:\n",
    "            return path\n",
    "\n",
    "        for adjacent in getadjacent(pixel):\n",
    "            x,y = adjacent\n",
    "            if iswhite(pixels[x,y]):\n",
    "                pixels[x,y] = (127,127,127) # see note\n",
    "                new_path = list(path)\n",
    "                new_path.append(adjacent)\n",
    "                queue.put(new_path)\n",
    "\n",
    "    #print \"Queue has been exhausted. No answer was found.\"\n",
    "\n",
    "\n",
    "\n",
    "    # invoke: python mazesolver.py <mazefile> <outputfile>[.jpg|.png|etc.]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "direct_paths=[]\n",
    "\n",
    "def ifPathExists(vertForCropping, rect1_centre, rect2_centre):\n",
    "    getNewVertForCropping(vertForCropping, rect1_centre, rect2_centre)\n",
    "    base_img = Image.open(\"blackRectNewNeg.png\")\n",
    "    base_pixels = base_img.load()\n",
    "\n",
    "    path = BFS(rect1_centre, rect2_centre, base_pixels)\n",
    "\n",
    "    path_img = Image.open(\"blackRectNewNeg.png\")\n",
    "    path_pixels = path_img.load()\n",
    "    \n",
    "    try:\n",
    "        for position in path:\n",
    "            x,y = position\n",
    "            path_pixels[x,y] = (255,0,0) # red\n",
    "\n",
    "        path_img.save('sjhdjk.png')\n",
    "        print 'Path found between' , rect1_centre, ' and ', rect2_centre\n",
    "        direct_paths.append([rect1_centre,rect2_centre])\n",
    "        return True\n",
    "    except:\n",
    "        print 'No path found between' , rect1_centre, ' and ', rect2_centre\n",
    "        return False\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((273, 316), (1021, 495)), ((273, 316), (684, 496)), ((273, 316), (788, 277)), ((273, 316), (521, 100)), ((1021, 495), (684, 496)), ((1021, 495), (788, 277)), ((1021, 495), (521, 100)), ((684, 496), (788, 277)), ((684, 496), (521, 100)), ((788, 277), (521, 100))]\n"
     ]
    }
   ],
   "source": [
    "# getting all the combinations\n",
    "#a = iter(list(range(len(centres))))\n",
    "a = iter(centres)\n",
    "import itertools\n",
    "combinations=[]\n",
    "combinations.extend(itertools.combinations(a, 2))\n",
    "print combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dict_nodes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-b9b4e65cfe28>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mlist_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict_centre_names\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0mdict_nodes\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mnode_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dict_nodes' is not defined"
     ]
    }
   ],
   "source": [
    "from anytree import Node, RenderTree\n",
    "client_name = \"Company A\"\n",
    "\n",
    "'''\n",
    "text_node_names=[]\n",
    "for name in dict_centre_names.values():\n",
    "    if name == client_name:\n",
    "        print (name)\n",
    "        text_node_names.append(name)\n",
    "        client_root = Node(client_name)\n",
    "        \n",
    "    else:\n",
    "        print (name)\n",
    "        text_node_names.append(name)\n",
    "        name = Node(name)\n",
    "        \n",
    "        \n",
    "'''\n",
    "    \n",
    "\n",
    "list_names = dict_centre_names.values()\n",
    "\n",
    "print dict_nodes\n",
    "    \n",
    "node_index = 0\n",
    "def build_tree(rect1_centre, rect2_centre):\n",
    "    \n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #............find which of r1 and r2 is the child of the other..........#\n",
    "\n",
    "    #rect1 is parent of rect2 (comapre y coordinates)\n",
    "    if rect1_centre[1] < rect2_centre[1]:\n",
    "        node_index = Node(dict_centre_names[rect2_centre])\n",
    "        rect2_index.parent = rect1_index \n",
    "        \n",
    "    else:\n",
    "        rect1 = Node (dict_centre_text[rect2_centre], parent = rect2)\n",
    "\n",
    "def print_tree():\n",
    "    for pre, fill, node in RenderTree(client_root):\n",
    "        print(\"%s%s\" % (pre, node.name))\n",
    "        \n",
    "def print_subtree(node):\n",
    "\n",
    "    from anytree.dotexport import RenderTreeGraph\n",
    "    print(RenderTree(node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#finding if path is possible b/w all the combinations of rectnagles\n",
    "num_of_direct_paths = 0\n",
    "\n",
    "for c in combinations:\n",
    "    #print 'Verts of rectangles being considered'\n",
    "    #print dict_centre_vert[c[0]]\n",
    "    #print dict_centre_vert[c[1]]\n",
    "\n",
    "    if (ifPathExists( vertForCropping, c[0], c[1])):\n",
    "        num_of_direct_paths = num_of_direct_paths + 1\n",
    "        #build_tree (c[0] , c[1])\n",
    "        #print_tree()\n",
    "    #ifPathExists( vertForCropping,[(vertForCropping[c[0]][0][0],vertForCropping[c[0]][0][1]),(vertForCropping[c[0]][1][0],vertForCropping[c[0]][1][1])],[(vertForCropping[c[1]][0][0],vertForCropping[c[1]][0][1]),(vertForCropping[c[1]][1][0],vertForCropping[c[1]][1][1])])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print num_of_direct_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from anytree import Node, RenderTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_names = dict_centre_names.values()\n",
    "dict_nodes= dict(enumerate(list_names))\n",
    "\n",
    "print dict_nodes\n",
    "\n",
    "udo = Node(\"Udo\")\n",
    "for node_index in dict_nodes.keys():\n",
    "    node_index = Node(dict_nodes[node_index], parent=udo)\n",
    "\n",
    "\n",
    "for pre, fill, node in RenderTree(udo):\n",
    "        print(\"%s%s\" % (pre, node.name))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from treelib import Node, Tree\n",
    "tree = Tree()\n",
    "l= ['company a', 'mr a','b','c']\n",
    "tree.create_node(l[0], l[0])  # root node\n",
    "for i in range(1 , 4):\n",
    "    tree.create_node(l[i], l[i], parent=l[0])\n",
    "tree.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print dict_centre_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print direct_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for dp in direct_paths:\n",
    "    print dict_centre_names[dp[0]],dict_centre_names[dp[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#find parent and child from direct_paths\n",
    "#and putting them in dictionay\n",
    "parentChildDict=dict()\n",
    "print \"parent   |   child\"\n",
    "for dp in direct_paths:\n",
    "    y1 = dp[0][1]\n",
    "    y2 = dp[1][1]\n",
    "\n",
    "    if y1>y2:\n",
    "        print dict_centre_names[dp[1]],dict_centre_names[dp[0]]\n",
    "        if dict_centre_names[dp[1]] in parentChildDict.keys():\n",
    "            parentChildDict[dict_centre_names[dp[1]]].append(dict_centre_names[dp[0]])\n",
    "            \n",
    "        else:    \n",
    "            parentChildDict[dict_centre_names[dp[1]]] =[dict_centre_names[dp[0]]]\n",
    "            \n",
    "    else:\n",
    "        print dict_centre_names[dp[0]],dict_centre_names[dp[1]]\n",
    "        parentChildDict[dict_centre_names[dp[0]]] = [dict_centre_names[dp[1]]]\n",
    "        if dict_centre_names[dp[0]] in parentChildDict.keys():\n",
    "            parentChildDict[dict_centre_names[dp[0]]].append(dict_centre_names[dp[1]])\n",
    "          \n",
    "        else:    \n",
    "            parentChildDict[dict_centre_names[dp[0]]] =[dict_centre_names[dp[1]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print parentChildDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getChildren(p):\n",
    "    for key in parentChildDict:\n",
    "        if p == key:\n",
    "            return parentChildDict[p]\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# owners of the client company\n",
    "import Queue\n",
    "\n",
    "q = Queue.Queue()\n",
    "\n",
    "client = 'Company A'\n",
    "#initially p = client\n",
    "q.put(client)\n",
    "\n",
    "#use queue to go through down the whole tree\n",
    "while not q.empty():\n",
    "    p=q.get()\n",
    "    if getChildren != []:\n",
    "        for c in getChildren(p):\n",
    "            q.put(c)\n",
    "    print p,\"has the ownership\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
